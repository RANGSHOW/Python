{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ___Time Series with Pandas___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ___DataTime Index___\n",
    " - #### time 또는 date 정보는 별개의 칼럼이기보다 인덱스인 경우가 많습니다.\n",
    " - #### Pandas 에 내장된 기능들로 DateTime Index를 생성하고 활용하는 방법을 다룹니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import mglearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime(2020, 4, 14)    # 뒤에 시, 분을 hyper parameter로 주지 않으면 0, 0으로 assign된다.\n",
    "    # 시간을 할당한 것: today = datetime(2020, 4, 14, 01, 30)\n",
    "    # type(today) == datetime.datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = [datetime(2020, 4, 13), datetime(2020, 4, 14)]\n",
    "    #type(dates[0]) == datetime.datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_time = pd.DatetimeIndex(dates)    # 가장 기본적인 Datetime Index 생성하는 방법\n",
    "    # type(dt_time) == pandas.core.indexes.datetimes.DatetimeIndex\n",
    "    # len(dt_time) == 2\n",
    "    # type(dt_time[0]) == pandas._libs.tslibs.timestamps.Timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_index = pd.DatetimeIndex(dates)    #dt_index == DatetimeIndex(['2020-04-13', '2020-04-14'], dtype='datetime64[ns]', freq=None)\n",
    "data = np.random.randn(2, 2)    # 임의의 2X2 데이터 생성\n",
    "    # type(data) == numpy.ndarray\n",
    "cols = ['A', 'B']    # 임의의 column name 생성\n",
    "\n",
    "df = pd.DataFrame(data=data, index=dt_index, columns=cols)   # DataFrame 생성의 기본 형태\n",
    "    # dt_index 가 index 이므로 굵게 표시가 되었다\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = pd.DataFrame(data=data, index=dt_index, columns=cols).reset_index()   # DataFrame 생성의 기본 형태\n",
    "    # 별도의 index 가 numeric 형태로 default로 assign 되고 object type으로 datetime이 저장된다\n",
    "df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index    # df(dataframe)의 index 확인\n",
    "df.index.max() \n",
    "df.index.min()\n",
    "\n",
    "df.index.argmax()\n",
    "df.index.argmin()\n",
    "    # index.argmax() 는 index 중에 가장 큰 값의 index의 offset을 반환한다 (e.g. 0, 1, 2, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/apple_stock.csv')\n",
    "# df.head()\n",
    "    # df(apple_stock) 에서는 datetime을 index로 지정해놓지 않았다. (아직 0, 1, 2, ... 같은 numeric index)\n",
    "# df.info()\n",
    "    # Date 라는 column이 object type으로 있다. Pandas에서 object라는 것은 integer, float, numeric 이 아니면 다 object type로 나온다.(string도 object type)\n",
    "    # => Date 를 데이터로 바꾸고 index로 지정해주면 된다\n",
    "\n",
    "# df['Date']\n",
    "    # Date 라는 column은 Series 객체인데 dtype은 object 이다\n",
    "# df['Date'].apply(pd.to_datetime)\n",
    "    # Date 라는 Series Object의 data type 이 datetime으로 바뀐 것을 확인할 수 있다.\n",
    "df['Date'] = df['Date'].apply(pd.to_datetime)\n",
    "    # Date Column에 덮어써주면 Date Column은 object type 에서 datetime type으로 data type을 바꿀 수 있다.\n",
    "df.set_index('Date', inplace=True)\n",
    "    #'Date' Column을 df의 index로 변경, \"inplace=True\"는 해당 변경 사항을 유지한다\n",
    "df.head()\n",
    "    # 'Date' Column이 Index로 바뀌어있는 걸 확인할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About ___DataFrame___ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ___DataFrame___은 ___Index + Series + Series + Series + ...___ 와 같은 형태이다\n",
    "#### ___row 별로 접근___할 때는 ___슬라이싱___으로 접근한다 e.g) df[0:1]\n",
    "#### ___column 별로 접근___할 때는 해당 ___Series의 이름___을 넣어주면 된다 e.g) df['Close']\n",
    "#### column 별로 접근할 때, numpy.ndarray 와 같이 df[:, 1] 등의 접근은 불가능하다\n",
    "#### ___하나의 요소___에 접근할 때, ___df ['column_name'] [index_num]___로 접근한다.\n",
    "#### ___하나의 요소___에 접근할 때, ___df ['column_name'] [start: end]___로 접근한다.\n",
    "#### ___하나의 요소___에 접근할 때, ___df [index_num] ['column_name']___로 접근한다.\n",
    "#### ___하나의 요소___에 접근할 때, ___df [start: end] ['column_name']___로 접근한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - #### DataFrame 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_df = pd.DataFrame(data=[[1, 2, 3], [4, 5, 6], [7, 8, 9]], index=['r0', 'r1', 'r2'], columns=['c0', 'c1', 'c2'])\n",
    "ex_df2 = pd.DataFrame(np.random.randint(1, 9, (3, 3)), ['r0', 'r1', 'r2'], ['c0', 'c1' ,'c2'])\n",
    "    # randint(low, high, shape) <-> randn(shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About ___Series___ \n",
    " - #### Pandas에서 제공하는 DataFrame과 함께, 제공하는 데이터 구조의 하나로 index와 values로 구성되어있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary로 Series Object 생성하기\n",
    "dict_data = dict(zip(['A', 'B', 'C', 'D', 'E', 'F'], ['Alpha', 'Bravo', 'Charlie', 'Delta', 'Echo', 'Foxtrot']))\n",
    "series_data = pd.Series(dict_data)\n",
    "print(type(series_data), '\\n', series_data)\n",
    "    # Key는 index로, value는 value로 변환되어 Series 객체를 생성한다.\n",
    "series_data.index    # Index(['a', 'b', 'c'], dtype='object')\n",
    "series_data.values    # array([1, 2, 3], dtype=int64)\n",
    "\n",
    "\n",
    "\n",
    "# List로 Series Object 생성하기\n",
    "list_data = ['Alpha', 'Bravo', 'Charlie', 'Delta', 'Echo', 'Foxtrot']\n",
    "series_data = pd.Series(list_data)\n",
    "print(type(series_data), '\\n', series_data)\n",
    "    #key는 numeric으로 list value가 values로 변환되어 Series 객체를 생성한다.\n",
    "    \n",
    "# tuple로도 만들 수 있다.\n",
    "\n",
    "# numeric index를 바꾸는 방법은\n",
    "# 1.\n",
    "series_data.index = (['A', 'B', 'C', 'D', 'E', 'F'])\n",
    "    # 와 같이 직접 assign하거나\n",
    "\n",
    "# 2.\n",
    "alpha = ['A', 'B', 'C', 'D', 'E', 'F']\n",
    "series_data_2 = pd.Series(list_data, index=alpha)\n",
    "    # 와 같이 생성시 index parameter에 전달해주어도 된다.\n",
    "    \n",
    "specipic_val = series_data_2.values[0:2].tolist()\n",
    "specipic_ind = series_data_2.index[0:2].tolist()\n",
    "    # Series data 에서 ndarray type(values, index)을 slicing 하여 list type 으로 transform\n",
    "    \n",
    "# 결측치 처리\n",
    "# np.series.fillna()    <- fillna(series.mean()), fillna(0) 등을 사용할 수 있다\n",
    "my_series = pd.Series([100, 300, None, 500, 750])\n",
    "my_series = my_series.fillna(0)\n",
    "my_series = pd.Series([100, 300, None, 500, 750])\n",
    "my_series = my_series.fillna(my_series.mean())\n",
    "my_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ___Time Resampling___\n",
    " - #### 시계열 데이터의 인덱스는 시(hour), 분(minutes) 등 작은 DateTime Index로 이루어진 경우도 많습니다.\n",
    " - #### 더 넓은 주기로 데이터를 집계(aggregate)해야 하는 경우 Time Resampling이 필요합니다.\n",
    " - #### groupby를 사용함으로써 Time Resampling을 수행할 수 있지만, 비지니스 도메인에서 분기나 회계년도를 편리하긴 힘듭니다.\n",
    " - #### Pandas는 이런 경우에 활용할 수 있는 frequency sampling 도구를 지원합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time Resampling을 몰랐을 때 aggregation(집계, 집합 정도?) 하고 싶을 때\n",
    "# 여기서는 monthly data 를 얻고 싶을 때 (월 합계, 등)\n",
    "df.index.month    # index 가 datetime 형태이기 때문에 .month로 꺼내올 수 있다\n",
    "df['month'] = df.index.month\n",
    "    # df에 'month' 라는 Column을 만들어서 저장\n",
    "    \n",
    "df.groupby('month').agg(sum)     # agg() == aggregate()\n",
    "    # 'month' Column으로 groupby 한 다음에 sum으로 aggregation 한다\n",
    "    # 하지만 이렇게 하면 년도 구별이 되어있지 않다는 점이다\n",
    "\n",
    "# 물론 이 문제도 groupby()로 해결할 수 있다\n",
    "df.groupby(df.index.year).sum()\n",
    "    # 이렇게 하면 조금 전과 같은 의도치 않은 통합을 막을 수 있다\n",
    "\n",
    "df.groupby([df.index.year, df.index.month]).agg(sum)    # groupby의 두 번째 Index를 그냥 'month' Column으로 줘도 된다\n",
    "    # multi-index를 준 다음에 aggregation 하면 된다\n",
    "    # 하지만 이렇게 하면 multi-index 를 다루어야 하는 동시에 여러 부수적인 일을 추가로 해주어야 한다\n",
    "    # 그래서 Pandas에서는 resample 이라는 것을 만들어 편리하게 사용할 수 있게 해준다\n",
    "    # offset_alises 를 찾아보면서 resampling 하면 된다\n",
    "    \n",
    "# 위에서 yearly groupby 했던 건 이렇게 하면 된다\n",
    "df.resample(rule='A')    # 까지 입력하면 Resampler object가 나오고 Aggregation 함수를 호출하면 된다\n",
    "df.resample(rule='A').sum()\n",
    "df.resample(rule='A').mean()\n",
    "    # resample 한 후 datetime index를 계속 사용할 수 있어서 강력한 기능이라 할 수 있다\n",
    "df.resample(rule='A').mean()['2009']\n",
    "    # 이렇게 datetime index의 indexing 기능할 활용하려면 Resample을 이용해야한다\n",
    "    # 만약 Groupby를 사용했다면 이런 식으로 range selection 을 할 수 없다 (Groupby를 사용한다면 다시 indexing 을 해야하는 불편함이 생긴다)\n",
    "    # rule 로 지정할 수 있는 alias 하이퍼 파라미터 말고도 custom 으로 Resample 할 수 있다\n",
    "    \n",
    "# 가령 매년 첫째 날 값을 뽑고싶을 때,\n",
    "\n",
    "#2. 우선, apply()안에 들어오는 sample은 1년 단위로 들어온다. 그 1년 단위의 첫 번째 값만 Return하는 함수 'first_day'를 만든다\n",
    "def first_day(sample):\n",
    "    return sample[0]\n",
    "    \n",
    "df.resample(rule='A').apply(first_day)   #1. aggregation function을 다는 대신에 apply를 해준다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling을 이용하면 Chart를 만들 때에도 유용하다\n",
    "\n",
    "#1. 가령 '종가(close)'의 연편균을 Bar Chart로 그려라 라고 한다면,\n",
    "df['Close'].resample('A').mean()   # rule은 첫 번째 파라미터이기에 positional argement로 사용하여도 된다\n",
    "    # 이렇게 mean() 까지 입력하면 pandas.Series object가 return 된다\n",
    "df['Close'].resample('A').mean().plot(kind='bar')\n",
    "    # Apple 주식이라 올라가기만 하고 떨어지지는 않는다\n",
    "    \n",
    "#2. Open 가격의 월별 최대값을 Bar Chart로 그려라 라고 한다면, \n",
    "df['Open'].resample('M').max().plot(kind='bar', figsize=(15,8))    # 데이터가 많기 때문에 figsize=shape 를 통해 키웠다\n",
    "    # 계속 올라가는 추세였으나 최근 조금 떨어지고 있다\n",
    "    # datetime index 이기 때문에 범위 제한도 바로 할 수 있다\n",
    "df['Open']['2015':].resample('M').max().plot(kind='bar', figsize=(15,8))    # 2015년 이후 데이터만\n",
    "df['Open']['2015-08':].resample('M').max().plot(kind='bar', figsize=(15,8))    # 2015년 8월 이후 데이터만\n",
    "    # ['2015-8'], ['2015.08'], ['2015/08'] 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datetime index를 규칙에 따라 만들어주는 function\n",
    "daily_daterange = \\\n",
    "pd.date_range(\n",
    "    start=datetime(2018,9,1), \n",
    "    end=datetime(2019,1,24), \n",
    "    freq='B')    # freq='B', 즉 Business 기준으로 만들면 토요일, 일요일이 없다 (Business Day만 indexing)\n",
    "    # Pandas가 아니었다면 날짜마다 loop를 돌며 토요일인지 일요일 인지 확인해서 빼야하는 번거러움이 있었을 것이다\n",
    "\n",
    "# 이제 인덱스(daily_daterange)가 생겼으니 이를 이용하는 데이터를 만들어보자\n",
    "daily_dataset = \\\n",
    "pd.DataFrame(\n",
    "    data={'value': np.random.rand(len(daily_daterange))}, \n",
    "    index=daily_daterange)\n",
    "\n",
    "daily_dataset.head(10)\n",
    "    # 08, 09 일이 빠져있다 (주말이기 떄문에 Index에서 제외되었다)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이 daily_dataset을 Resampling 해보자\n",
    "#1. 해당 주의 minimum 값을 월요일 값으로 표시하려면,\n",
    "daily_dataset.resample('W-MON').min()\n",
    "    # 모두 월요일만 indexing 되었고 해당 주의 minimum 값이 해당 cell의 value로 assign되었다\n",
    "    # W(eekly) 뒤에 MON TUE 같은 요일을 붙여 다양한 Resampling 응용을 가능하게 한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_dataset.resample('M').min()\n",
    "    # Monthly Resampling은 기본적으로 해당 달의 마지막 날을 Index로 사용하게 된다\n",
    "    # 만약에 Groupby로 한다면, 해당 달의 마지막 날을 가져오는 데에도 힘이 들 수 있다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ___Time Shifting___\n",
    " - #### 시계열 분석 알고리즘을 사용하기 위해 데이터를 임의 시간만큼 앞 또는 뒤로 이돌시켜야 할 때가 있습니다.\n",
    " - #### Pandas는 이런 경우에도 매우 쉬운 방법을 제공합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다시 Apple Stock 데이터를 읽을게요..\n",
    "df = pd.read_csv('data/apple_stock.csv', index_col='Date')\n",
    "    # 원 데이터에는 Data라는 Column이 Column의 형태로 있었는데 바로 Index로 읽어들인다. set_index()를 할 필요가 사라진다\n",
    "df.index\n",
    "    # datetime type 이 아니라 object type(구체적으로는 string type) 이다\n",
    "# df['2009'] \"2009년만 가져와라\" => 택도 없습니다.. \n",
    "\n",
    "# index를 datetime 형태로 바꿔주자\n",
    "df.index = pd.to_datetime(df.index)\n",
    "df.index\n",
    "    # datetime type으로 바뀐 걸 확인할 수 있다\n",
    "    \n",
    "# index를 datetime index로 바꾸는 방법\n",
    "#1. Date Column에 DataFrame.apply(to_datetime)으로 datetime index로 변환 후, pd.set_index(Data) 한다\n",
    "#2. index를 to_datetime()을 통해 datetime으로 만들고 df.index에 덮어썼다 (이미 pd.read_csv()에서 Date를 index로 지정)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = np.asarray(df['Close'])   # asarray()는 객체를 참조한다\n",
    "temp[:-1]\n",
    "temp[1:]\n",
    "    # 이렇게 2가지 temp 버전은 <<1 Shifting 된 형태이다\n",
    "    # 허나 이렇게 모든 Column을 하기 번거롭다\n",
    "    # 따라서 Pandas에서는 DataFrame.shift() 라는 함수를 제공한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shift(1).head()    # DF.shift() 안에는 얼마나 shifting 할 지 hyper-parameter를 지정해준다 (1이면 한 칸씩 뒤로 민다)\n",
    "    # 이렇게 하면 첫번째 row는 모두 결측치가 된다 = 데이터를 잃게 된다\n",
    "    # 이것은 Pandas 만의 문제가 아니라 Time Shifting 하는 것의 숙명이죠.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shift(-1).tail()\n",
    "    # 한 칸씩 앞으로 보내면 Missing Data 가 맨 끝 row 에서 발생하게 된다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 후반부에 가면 lagging, lag, lagged data 등으로 부른다 \"한 차원 래깅했다\"라고 말한다\n",
    "# 위와 같이 lagging 할 차원수를 줘서 shifting 하는 법만 있는게 아니라 tshift(Time Shift)도 있다\n",
    "df.tshift(freq='M', periods=1).head()    # periods가 12면 1년 만큼 shifting 하는 것이다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Difference btw ___np.array()___ and ___np.asarray()___\n",
    " - #### np.array() 는 단순히 값만을 복사한다 (___copy=True___)\n",
    " - #### np.asarray() 는 원본을 참조한다 (값을 바꾸면 원본도 바뀜. ___copy=false___)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_0 = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "\n",
    "arr_1 = np.array(arr_0)\n",
    "arr_1[0, :] = [10, 10, 10]\n",
    "\n",
    "arr_2 = np.asarray(arr_0)\n",
    "arr_2[1, :] = [20, 20, 20]\n",
    "\n",
    "arr_0\n",
    "    # arr_1에서는 값이 바뀌지만 arr_0에서는 바뀌지 않는다\n",
    "    # arr_2에서 값이 바뀌고 arr_0에서도 값이 바뀐다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ___Rolling___\n",
    " - #### 매일 수집한 데이터들에는 노이즈가 포함되기도 합니다.\n",
    " - #### 이럴 경우 데이터의 일반적인 트렌드를 구하기 위해 rolling mean (또는 moving average)을 사용하기도 합니다.\n",
    " - #### Pandas 에 내장된 rolling 함수를 이용하면 주어진 시한 내 평균 (rolling mean) 등을 구할 수 있습니다.\n",
    " - #### 임의 시간 간격의 window 를 만들고 그 안에서 mean 같은 통계적 aggregation을 실행하면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 또 한 번 Apple Stock을 읽을게요.. 이번에는 또 다른 방법입니다..\n",
    "df = pd.read_csv('data/apple_stock.csv', \n",
    "                 index_col='Date', parse_dates=True)\n",
    "    # 'parse_dates' parameter를 통해 Date를 Parsing 할 수 있다\n",
    "    # Column을 검사해서 Parsing 할 수 있는 형태의 칼럼을 발견하면 datetime type으로 변환한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 또한 parse_dates 의 parameter로 True 대신에 List type을 줄 수도 있다\n",
    "pd.read_csv('data/apple_stock.csv',\n",
    "           index_col='Date', parse_dates=['Date'])    # 변환하길 원하는 Column을 직접 지정할 수 있다\n",
    "    # parse_dates=True 만 했을 때는 변환이 안될 수도 있기에 직접 Column을 지정(여기서는 'Date') 해줌으로써 에러를 방지한다\n",
    "    # 그렇다면 Parsing이 안되는 Column은 어떻게 하느냐? e.g) '2019-JAN-01', '19-01-01'\n",
    "    \n",
    "# Parsing이 안되는 경우 Parsing Function을 만들어 줘야한다\n",
    "def  selfmade_date_parser(str_dt):\n",
    "    return pd.datetime.strptime(str_dt, \"%Y-%m-%d\")    # stptime() function은 'string parse time'이라는 뜻이다\n",
    "\n",
    "df = pd.read_csv('data/apple_stock.csv',\n",
    "                index_col='Date',\n",
    "                parse_dates=['Date'],\n",
    "                date_parser=selfmade_date_parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selfmade_date_parser 확인\n",
    "selfmade_date_parser('2020-01-01')\n",
    "def  selfmade_date_parser_2(str_dt):\n",
    "    return pd.datetime.strptime(str_dt, \"%d-%m-%Y\")\n",
    "    # 만약 datetime 의 format이 dd-mm-yyyy 일 때는 이렇게 바꾸어준다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7일 짜리 rolling mean 을 구해볼게요..\n",
    "df.rolling(7)    # rolling()의 parameter로 periods가 들어온다. 7개 짜리 윈도우를 만들어서 옮겨가면서 Sampling을 한다. 각 sample 별로 7개씩 데이터가 들어온다\n",
    "df.rolling(7).mean()    # 들어온 7개의 데이터를 mean aggregation 해주면 된다\n",
    "    # 7일치가 rolling이 되었기 때문에 앞에 7개는 데이터가 모자라다\n",
    "    # 7일이 되기 전까지는 7개가 안차기 때문에 결측치로 나타난다\n",
    "    # rolling 하는 periods 만큼 Missing Data가 발생할 수 밖에 없다\n",
    "    \n",
    "# rolling() 함수는 Moving Average, 트렌드를 구하기 위해 사용한다\n",
    "# e.g) 주식의 Close 가격의 트렌드를 보고싶다\n",
    "df.rolling(window=30).mean()['Close'].plot(figsize=(20,4))\n",
    "df['Close'].plot()    # 원래 데이터(주황)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2018년만 일단 본다면,\n",
    "df['2018':].rolling(30).mean()['Close'].plot(figsize=(20,4))\n",
    "df['2018':]['Close'].plot()\n",
    "    # Moving average의 문제가 뒤따라간다는 것이다 \n",
    "    # window size 가 커질수록 실제를 반영하기 힘들어진다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['2018':].rolling(7).mean()['Close'].plot(figsize=(20,4))\n",
    "df['2018':]['Close'].plot()\n",
    "    # window=7로 바꾼다면 더 빨리 따라가는 트렌드 곡선을 볼 수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Close: 30 Day Mean'] = df['Close'].rolling(30).mean()\n",
    "df[['Close', 'Close: 30 Day Mean']].plot(figsize=(20,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ___Expanding___\n",
    " - #### 매일 수집한 데이터들에는 노이즈가 포함되기도 합니다.\n",
    " - #### 이럴 경우 데이터의 일반적인 트렌드를 구하기 위해 rolling mean (또는 moving average)을 사용하기도 합니다.\n",
    " - #### Pandas 에 내장된 rolling 함수를 이용하면 주어진 시한 내 평균 (rolling mean) 등을 구할 수 있습니다.\n",
    " - #### 임의 시간 간격의 window 를 만들고 그 안에서 mean 같은 통계적 aggregation을 실행하면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 만약 \n",
    "a_list = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]    # 이라는 리스트가 있다면 \n",
    "# rolling(window=2)은 (1, 2), (2, 3), (3, 4), (4, 5), ... 와 같이 틀(window)를 고정시키고 한 칸씩 이동하며 Aggregation한다\n",
    "# expand는 시점을 고정하고 (1), (1, 2), (1, 2, 3), (1, 2, 3, 4), ... 와 같이 periods만큼 늘려가면서 expand 하는 것을 expanding 이라고 한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Close'].expanding(min_periods=1).mean().plot()    # 종가의 누적 평균을 Plotting 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apple Stock Price로 볼린져 밴드 그려보기\n",
    "# df['Close'].rolling(20)에  +std*2 와 -std*2 해서 그려주면 된다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Close: 20Day Mean'] = df['Close'].rolling(20).mean()\n",
    "df['Upper'] = df['Close: 20Day Mean'] + 2 * df['Close'].rolling(20).std()\n",
    "df['Lower'] = df['Close: 20Day Mean'] - 2 * df['Close'].rolling(20).std()\n",
    "df['2018':][['Close', 'Close: 20Day Mean', 'Upper', 'Lower']].plot(figsize=(30, 10))    # 2018년 이후만 보고싶어서 ['2018':]를 추가해줬다\n",
    "    # 볼린저 밴드는 Upper 보다 위에 있을 때 사고 Lower 보다 밑에 있을 때 팔아야하는 지표로 이용되기도 한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
